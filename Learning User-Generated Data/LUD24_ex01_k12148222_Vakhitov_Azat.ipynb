{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2024*\n",
    "# Exercise 1: RecSys Basics II\n",
    "In this exercise we familiarize ourselves with recommender systems, a kind of data they use and implement a simple base-line recommendation algorithm.\n",
    "\n",
    "The assignment submission deadline is 19.03.2024 12:00.\n",
    "Please, don't forget to rename your Jupyter Notebook according to the convention:<br>\n",
    "\n",
    "LUD24_ex01_**k**<font color='red'>\\<Matr. Number\\></font>_<font color='red'>\\<Surname-Name\\></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD24_ex01_**k**0000007_Bond-James.ipynb\n",
    "\n",
    "## Introduction\n",
    "* What are recommender systems?\n",
    "* Where do we encounter them?\n",
    "* What part does User-generated Data play in RecSys?\n",
    "\n",
    "## Recommendation Scenario\n",
    "Imagine a platform where users consume items: buy goods (Amazon), listen to music tracks (Deezer, Spotify), watch movies (Netflix) or videos (YouTube).\n",
    "\n",
    "At some point a user may face a choice: \"what item should I have a look at next?\" Can be that they don't know what exactly they need and are unable to formulate a query. Of course with catalogs of millions of items they have little chance finding something useful by browsing through all of them.\n",
    "\n",
    "In such situations Recommender Systems are expected to make the decision easier for the user by shrinking the scope to a handful of individually selected options, for example top 10 recommended songs.\n",
    "\n",
    "Information the recommendation can be based on:\n",
    "* Items already consumed by the user\n",
    "* Items consumed by other users\n",
    "* User relations\n",
    "* Item meta-data & content\n",
    "* ...\n",
    "\n",
    "User-Item interactions is one of the most widely used signals in recommendation. Initially it can be available in a form of system logs (see table below). There is a multitude of ways a user can interact with an item: consume (buy, watch, listen), note (like, save to favorites), share and others. In this exercise we only deal with item consumption.\n",
    "\n",
    "#### Example: Raw User-Item Interactions Data\n",
    "| Meaningless but Unique<br>Event Id | User Id | Item Id | Event Type | Date |\n",
    "| ---         |---  |--- |---   |   ---    |\n",
    "| 002Ax4gf... | 12  | 2  | 6000 | 13.04.08 |\n",
    "| 9f2D4jKx... | 908 | 2  | 6000 | 01.02.09 |\n",
    "| 3g6lP89qs.. | 12  | 13 | 4800 | 11.10.10 |\n",
    "| ...         | ... |... | ...  | ...      |\n",
    "\n",
    "## Datasets\n",
    "Throughout the whole exercise track we will be mostly working on music & movie recommendation tasks. Note that all methods we consider are applicable to other domains!\n",
    "\n",
    "[LFM-2b](http://www.cp.jku.at/datasets/LFM-2b/) is a large dataset of over two billion listening events, spanning across ~15 years, crawled from LastFM platform. It is supported with user demographics information and music track meta-data. In this exercise we take a look at a small sample of the aggregated LFM-2B (lfm-tiny) as well as MovieLens-1M dataset (ml-1m). Each of them consists of three files, in case of lfm-tiny it is:\n",
    "\n",
    "* 'lfm-tiny.inter' - data about user-track interactions;\n",
    "* 'lfm-tiny.item' - track-related information;\n",
    "* 'lfm-tiny.user' - user-related information;\n",
    "    \n",
    "And for ml-1m respectively:\n",
    "    \n",
    "* 'ml-1m.inter' - data about user-movie ratings;\n",
    "* 'ml-1m.item' - movie-related information;\n",
    "* 'ml-1m.user' - user-related information;\n",
    "\n",
    "### Important note:\n",
    "**'lfm-tiny.inter'** contains cumulative number of listening events per pair User-Track over the whole period;\n",
    "    \n",
    "**'ml-1m.inter'** contains **ratings** per pair User-Track on a scale from 1 to 5;\n",
    "\n",
    "**The interpretation of the interaction feedback (listening events or ratings) is usually up to the designer of a recommender system. In this course we treat any feedback as IMPLICIT FEEDBACK**.\n",
    "\n",
    "## Implicit feedback\n",
    "The MovieLens dataset provides us with ratings users give to movies, this allows us to judge if a user (dis)likes one movie more than the other.\n",
    "    \n",
    "However, we do not always have explicit information about whether a user likes or dislikes a certain item (and to which extent). In case of LFM-2B we only know how many times a user have interacted with a certain item. The fact of a single interaction with a track does not mean that the user enjoyed it, so how many interactions do we need to be sure?\n",
    "    \n",
    "Following the concept of **Implicit Feedback** we binarise our interaction data: to every pair **User** and **Item** we assign 1 - user sufficiently (enough times or gave a sufficiently high rating) interacted with the item **or** 0 - user did not interact with the item / did not enjoy it / unknown.\n",
    "    \n",
    "Very roughly speaking recommendation with implicit feedback is a binary classification problem: prediction of whether the user is going to interact with an item or not.\n",
    "\n",
    "## <font color='red'>TASKS</font>:\n",
    "\n",
    "Implement functions specified below. Please, don't change the signatures (names, parameters) and follow the specifications closely. Your implementation should not require any additional imports, apart from those already in the notebook.\n",
    "\n",
    "For testing purposes make sure the two dataset folders are placed in the same folder next to the .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1/3: Interaction Matrix (4 points)\n",
    "Interaction matrix is a common data structure used in some (not all) recommender algorithms. It is a matrix with dimensions: [number of users] times [number of items] known to the system. Every element in the matrix shows whether the given User ever interacted with the given Item. It can be done in a binary manner, as a probability or as a rating given by the User to the Item.\n",
    "\n",
    "**Write a function** that is able to create an interaction matrix from both ml-1m and lfm-tiny datasets. It receives three dataframes, dataset name and an int threshold value as input and returns a 2-dimensional numpy array with the corresponding interaction matrix, where **0** means the user didn't interact with the track on purpose or didn't like it (played the track \\< [threshold] times, or gave a rating \\< [threshold] in the case of ml-1m), **1** means the user listened to the track more than or equal to [threshold] times (or gave a rating that is higher or equal to [threshold] in the case of ml-1m).\n",
    "\n",
    "The first dimension of the matrix should correspond to users, second - to items.\n",
    "\n",
    "**Important note:** we introduce the threshold as a way to filter out interactions that are not necessarily meaningful (e.g. accidental playbacks or movies a user disliked).\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_implicit(users: pd.DataFrame,\n",
    "                        items: pd.DataFrame,\n",
    "                        interactions: pd.DataFrame,\n",
    "                        dataset_name: str,\n",
    "                        threshold=1) -> np.ndarray:\n",
    "    '''\n",
    "    users - pandas Dataframe, use it as loaded from the dataset;\n",
    "    items - pandas Dataframe, use it as loaded from the dataset;\n",
    "    interactions - pandas Dataframe, use it as loaded from the dataset;\n",
    "    dataset_name - string out of [\"lfm-tiny\", \"ml-1m\"], name of the dataset, used in case there are differences in the column names of the data frames;\n",
    "    threshold - int > 0, criteria of a valid interaction\n",
    "\n",
    "    returns - 2D np.array, rows - users, columns - items;\n",
    "    '''\n",
    "    iter_matr = np.zeros((users.shape[0], items.shape[0]), dtype=int)\n",
    "\n",
    "    if dataset_name == \"lfm-tiny\":\n",
    "        event_column = \"listening_events\"\n",
    "    elif dataset_name == \"ml-1m\":\n",
    "        event_column = \"rating\"\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset name {dataset_name} is not supported\")\n",
    "\n",
    "    user_iter = 0\n",
    "    for row in interactions.iterrows():\n",
    "        item_id = row[1][\"item_id\"]\n",
    "        item_user_id = row[1][\"user_id\"]\n",
    "        item_events = row[1][event_column]\n",
    "        if user_iter != item_user_id: user_iter += 1\n",
    "        if(item_events > threshold):\n",
    "            iter_matr[user_iter, item_id] = 1\n",
    "        else:\n",
    "            iter_matr[user_iter, item_id] = 0\n",
    "\n",
    "    return iter_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the data for both datasets, keep it as specified in the csv files\n",
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "users_lfm = read(\"lfm-tiny\", 'user')\n",
    "\n",
    "items_lfm = read(\"lfm-tiny\", 'item')\n",
    "interactions_lfm = read(\"lfm-tiny\", 'inter')\n",
    "\n",
    "users_ml = read(\"ml-1m\", 'user')\n",
    "items_ml = read(\"ml-1m\", 'item')\n",
    "interactions_ml = read(\"ml-1m\", 'inter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your solution:\n",
    "Run your function on the data discussed above and make sure that the result is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates interaction matrix for LFM dataset, choose the correct threshold for this dataset\n",
    "_interaction_matrix_test_lfm = inter_matr_implicit(users_lfm, items_lfm, interactions_lfm, \"lfm-tiny\", threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert _interaction_matrix_test_lfm is not None, \"Interaction Matrix should not be None!\"\n",
    "assert type(_interaction_matrix_test_lfm) == np.ndarray, \"Interaction Matrix should be a numpy array!\"\n",
    "assert _interaction_matrix_test_lfm.shape == (1194, 412), \"Shape of Interaction Matrix is wrong!\"\n",
    "assert np.array_equal(np.unique(_interaction_matrix_test_lfm),\n",
    "                      [0, 1]), \"Interaction Matrix should only contain 0 and 1!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creates interaction matrix for Movielens dataset, choose the correct threshold for this dataset\n",
    "_interaction_matrix_test_ml = inter_matr_implicit(users_ml, items_ml, interactions_ml, \"ml-1m\", threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert _interaction_matrix_test_ml is not None, \"Interaction Matrix should not be None!\"\n",
    "assert type(_interaction_matrix_test_ml) == np.ndarray, \"Interaction Matrix should be a numpy array!\"\n",
    "assert _interaction_matrix_test_ml.shape == (6040, 3883), \"Shape of Interaction Matrix is wrong!\"\n",
    "assert np.array_equal(np.unique(_interaction_matrix_test_ml), [0, 1]), \"Interaction Matrix should only contain 0 and 1!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2/3: POP Recommender (4 points)\n",
    "One of the most straightforward approaches to recommendation -- recommending the most popular items to every user. We call such recommender POP. It is a useful (and quite strong) baseline for creating more sophisticated systems and can be a default recommender, when there is no data available to build the recommendation upon (for example if the user has just joined the platform and haven't interacted with anything yet). Through the whole exercise track we only recommend items **not seen** by the user before (repeated consumption is out of our scope).\n",
    "\n",
    "**Write a function** that recommends [K] most popular items to a given user, **making sure that the user hasn't seen any of the recommended items before.**\n",
    "\n",
    "The function should take three arguments: np.array of arbitrary dimensions (supporting any number of users and items) in the format from task 1 (interaction matrix), user ID (int) and K (int > 0).\n",
    "Expected return: a list or a 1D array with [K] IDs of most popular items (sorted in the order of descending popularity) **not seen** by the user.\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recTopKPop(inter_matr: np.array,\n",
    "               user: int,\n",
    "               top_k: int) -> np.array:\n",
    "    '''\n",
    "    inter_matr - np.array from the task 1;\n",
    "    user - user_id, integer;\n",
    "    top_k - expected length of the resulting list;\n",
    "\n",
    "    returns - list/array of top K popular items that the user has never seen\n",
    "              (sorted in the order of descending popularity);\n",
    "    '''\n",
    "\n",
    "    indices = np.nonzero(inter_matr[user] == 1)[0]\n",
    "    sum_pop_items = np.sum(inter_matr, axis=0)\n",
    "\n",
    "    sum_pop_items[indices] = -1\n",
    "    top_pop = np.argsort(sum_pop_items)[::-1][:top_k]\n",
    "    \n",
    "    return top_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your solution:\n",
    "Run your function on the interaction matrix prepared before, make sure the input/output is correctly formatted.<br>\n",
    "Get the <b>top 10</b> recommendations for <b>user 0</b>.\n",
    "What are the tracks recommended to them? Would you like such recommendation? Will <b>user 0</b> like it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " track: Over You, artist: PandRezz\n",
      " track: Pure Desire, artist: Dan Denison\n",
      " track: Feelings, artist: M83\n",
      " track: Coming Of The Tide, artist: Amon Amarth\n",
      " track: Upside Down, artist: Drowning Pool\n",
      " track: By My Side, artist: Porches\n",
      " track: Fuckmylife666, artist: Against Me!\n",
      " track: Stain, artist: Spineshank\n",
      " track: Like An Animal, artist: The Glove\n",
      " track: Belong, artist: Roosevelt\n",
      "[2789 1178 1192  476  585 2502  589 1180 1539  108]\n",
      " movie_title: American Beauty, release_year: 1999\n",
      " movie_title: Star Wars: Episode V - The Empire Strikes Back, release_year: 1980\n",
      " movie_title: Star Wars: Episode VI - Return of the Jedi, release_year: 1983\n",
      " movie_title: Jurassic Park, release_year: 1993\n",
      " movie_title: Terminator 2: Judgment Day, release_year: 1991\n",
      " movie_title: Matrix, The, release_year: 1999\n",
      " movie_title: Silence of the Lambs, The, release_year: 1991\n",
      " movie_title: Raiders of the Lost Ark, release_year: 1981\n",
      " movie_title: Men in Black, release_year: 1997\n",
      " movie_title: Braveheart, release_year: 1995\n"
     ]
    }
   ],
   "source": [
    "# I dont like the recomendation of the tracks, but I'd watch all the movies provided in the popular list. I'm not sure if the user will like it. \n",
    "top_10 = recTopKPop(_interaction_matrix_test_lfm, 0, 10)\n",
    "\n",
    "for top in top_10:\n",
    "    track_name = items_lfm.loc[top, \"track\"]\n",
    "    artist = items_lfm.loc[top, \"artist\"]\n",
    "    print(f\" track: {track_name}, artist: {artist}\")\n",
    "\n",
    "top_10_m = recTopKPop(_interaction_matrix_test_ml, 0, 10)\n",
    "print(top_10_m)\n",
    "for top in top_10_m:\n",
    "    movie_title = items_ml.loc[top, \"movie_title\"]\n",
    "    release_year = items_ml.loc[top, \"release_year\"]\n",
    "    print(f\" movie_title: {movie_title}, release_year: {release_year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert type(top_10) == np.ndarray, \"Output should be an array.\"\n",
    "assert len(top_10) == 10, \"Length is not right.\"\n",
    "# these recommendations are correct for the lfm dataset, comment it out if you are using ml-1m\n",
    "assert np.array_equal(top_10, np.array([ 42,  43,  51,  96, 105, 151,  12, 104,  68, 150])), \"Wrong recommendations.\"\n",
    "# these recommendations are correct for the ml-1m dataset, comment it out if you are using lfm\n",
    "#assert np.array_equal(top_10_m, np.array([2789, 1178, 1192, 476, 585, 2502,  589, 1539, 1180, 108])), \"Wrong recommendations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3/3: POP Recommender Country (2 points)\n",
    "Use what you have learned in Task 2 and implement a new version of POP recommender that to each user recomends top_k unseen tracks, most popular among users from the same country as the user.\n",
    "\n",
    "The function needs to figure out the country of the target user (the one receiving recommendations), see what is popular in that country, and then recommend top items not seen by the user before.\n",
    "\n",
    "Please note the additional parameter **users**, Dataframe consisting of user data with a \"country\" column (think of the .user file in the dataset), use it well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recTopKPopByCountry(inter_matr: np.array,\n",
    "               user: int,\n",
    "               top_k: int,\n",
    "               users: pd.DataFrame) -> np.array:\n",
    "    '''\n",
    "    inter_matr - np.array from the task 1;\n",
    "    user - user_id, integer;\n",
    "    top_k - expected length of the resulting list;\n",
    "    users: pandas Dataframe consisting of user information for all users, requires a \"country\" column\n",
    "\n",
    "    returns - list/array of top K popular items that the user has never seen\n",
    "              (sorted in the order of descending popularity);\n",
    "    '''\n",
    "    # get users by country\n",
    "    user_by_country = users[users[\"country\"] == users.loc[user, 'country']].index.to_list()\n",
    "    # get inter_matr by users from the country \n",
    "    inter_matr_filtered = inter_matr[user_by_country, :]\n",
    "    # get indices that are marked as seen by user \n",
    "    indices = np.nonzero(inter_matr[user] == 1)[0]\n",
    "    # sum columns \n",
    "    sum_pop_items = np.sum(inter_matr_filtered, axis=0)\n",
    "    # mark seen items as negative\n",
    "    sum_pop_items[indices] = -1\n",
    "    # sort the items by popularity and return indices\n",
    "    top_pop = np.argsort(sum_pop_items)[::-1][:top_k]\n",
    "    return top_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check your solution:\n",
    "Run your function on the interaction matrix prepared before, make sure the input/output is correctly formatted.  Get the top 10 recommendations for user 0. What are the tracks recommended to them? Would you like such recommendation? Will user 0 like it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " track: Pure Desire, artist: Dan Denison\n",
      " track: Over You, artist: PandRezz\n",
      " track: Thank You, artist: Dave Brubeck\n",
      " track: Pound Cake / Paris Morton Music 2, artist: Drake\n",
      " track: Coming Of The Tide, artist: Amon Amarth\n",
      " track: O, artist: The Prodigy\n",
      " track: Fast Car - Radio Edit, artist: Jonas Blue\n",
      " track: Rock Around The Clock, artist: Telex\n",
      " track: Feelings, artist: M83\n",
      " track: Fireborn, artist: Stratovarius\n",
      " movie_title: Mortal Kombat, release_year: 1995\n",
      " movie_title: Restoration, release_year: 1995\n",
      " movie_title: From Dusk Till Dawn, release_year: 1996\n",
      " movie_title: Dangerous Minds, release_year: 1995\n",
      " movie_title: Shopping, release_year: 1994\n",
      " movie_title: Babe, release_year: 1995\n",
      " movie_title: Kicking and Screaming, release_year: 1995\n",
      " movie_title: Dracula: Dead and Loving It, release_year: 1995\n",
      " movie_title: Mighty Aphrodite, release_year: 1995\n",
      " movie_title: City Hall, release_year: 1996\n"
     ]
    }
   ],
   "source": [
    "inter_matr_lfm = inter_matr_implicit(users_lfm, items_lfm, interactions_lfm, \"lfm-tiny\", threshold=1)\n",
    "# create a pandas Dataframe with user data that has at least a \"country column\"\n",
    "users = users_lfm\n",
    "top_10 = recTopKPopByCountry(inter_matr=inter_matr_lfm, user=0, top_k=10, users=users)\n",
    "for top in top_10:\n",
    "    track_name = items_lfm.loc[top, \"track\"]\n",
    "    artist = items_lfm.loc[top, \"artist\"]\n",
    "    print(f\" track: {track_name}, artist: {artist}\")\n",
    "\n",
    "top_10_m = recTopKPopByCountry(inter_matr=inter_matr_lfm, user=0, top_k=10, users=users)\n",
    "#print(top_10_m)\n",
    "for top in top_10_m:\n",
    "    movie_title = items_ml.loc[top, \"movie_title\"]\n",
    "    release_year = items_ml.loc[top, \"release_year\"]\n",
    "    print(f\" movie_title: {movie_title}, release_year: {release_year}\")\n",
    "\n",
    "\n",
    "# I'd like to listen to some of the tracks and movies. I think the user 0 will like it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Wrong recommendations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(top_10) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput should be an array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(top_10) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength is not right.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(top_10, np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m43\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m69\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m65\u001b[39m])), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong recommendations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Wrong recommendations."
     ]
    }
   ],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert type(top_10) == np.ndarray, \"Output should be an array.\"\n",
    "assert len(top_10) == 10, \"Length is not right.\"\n",
    "assert np.array_equal(top_10, np.array([43, 42, 69, 30, 96, 33, 51, 11, 71, 65])), \"Wrong recommendations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final check\n",
    "* Your functions are going to be tested in isolation, make sure you don't use global variables;\n",
    "* Remove all the code you don't need, provide comments for the rest;\n",
    "* Check the execution time of your functions, if any of them takes more than one minute to execute on the given data, try optimizing it. Extremely inefficient solutions will get score penalties;\n",
    "* Don't forget to rename the notebook before submission;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell the way it is, please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
