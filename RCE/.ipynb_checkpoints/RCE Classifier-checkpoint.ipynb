{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479f6f93-13c3-4d82-bd69-f55cebc4cd00",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">RCE Sample:</h3>\n",
    "\n",
    "The dataset consists of images of musical notes labeled as Eight, Half, Quarter, Sixteenth, and Whole. The code carries out the following steps:\n",
    "\n",
    "Import necessary libraries: The script imports required libraries such as os, numpy, pandas, matplotlib, PIL (Python Imaging Library), torch, and scikit-learn.\n",
    "\n",
    "Load the dataset and create labels: The code defines a dictionary for label encoding and decoding\n",
    "\n",
    "Split the dataset: The dataset is split into training and testing sets using scikit-learn's train_test_split function.\n",
    "\n",
    "Load and preprocess images: The images are loaded using the PIL library, resized, and normalized to have values between -1 and 1.\n",
    "\n",
    "Define RCE functions: Two functions, euclidean_distance and rce, are defined to compute the Euclidean distance between two points and calculate the RCE value\n",
    "\n",
    "Further split the dataset: The preprocessed images and their corresponding labels are split again into training and testing sets.\n",
    "\n",
    "Set the theta parameter: The theta parameter is set to a value of 0.1. This can be adjusted based on the dataset.\n",
    "\n",
    "Train the RCE classifier: The RCE values for each image in the training set are computed and stored in a list.\n",
    "\n",
    "Classify the images in the testing set: The RCE values for each image in the testing set are computed and compared with the stored RCE values from the training set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2fc7e9-f3f5-4359-aa9d-e6ce79b1f5e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m train, test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m77\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Load and preprocess images\u001b[39;00m\n\u001b[0;32m     28\u001b[0m image_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset and create labels\n",
    "label_code = {'Eight': 0, 'Half': 1, 'Quarter': 2, 'Sixteenth': 3, 'Whole': 4}\n",
    "label_decode = ['Eight', 'Half', 'Quarter', 'Sixteenth', 'Whole']\n",
    "df = pd.DataFrame(columns=['path', 'label'])\n",
    "\n",
    "for dirname, _, filenames in os.walk('filesDir'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        name = dirname.split('\\\\')[-1]  # Change the separator to '\\\\'\n",
    "        label = label_code[name]\n",
    "        new_row = pd.DataFrame({'path': [path], 'label': [label]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=77)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_size = (100, 100)\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    img = Image.open(row['path']).convert('RGB').resize(image_size)\n",
    "    img = np.array(img, dtype='float32')\n",
    "    img = 1 - img / 127.5\n",
    "    images.append(img)\n",
    "    labels.append(row['label'])\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "# RCE functions\n",
    "def euclidean_distance(a, b):\n",
    "    return torch.sqrt(torch.sum((a - b) ** 2))\n",
    "\n",
    "def rce(a, b, theta):\n",
    "    distance = euclidean_distance(a, b)\n",
    "    return (1 / distance) * torch.exp(-distance / theta)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Move data to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "X_train = torch.tensor(X_train, device=device)\n",
    "X_test = torch.tensor(X_test, device=device)\n",
    "\n",
    "theta = 0.1  # You can adjust this parameter based on your dataset\n",
    "RCE_values = []\n",
    "\n",
    "# Train the RCE classifier\n",
    "for i in range(len(X_train)):\n",
    "    rce_val = rce(X_train[i], X_train, theta)\n",
    "    RCE_values.append(rce_val)\n",
    "\n",
    "RCE_values = torch.stack(RCE_values)\n",
    "\n",
    "# Classify the images in the testing set\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    rce_val = rce(X_test[i], X_train, theta)\n",
    "    closest_class = torch.argmin(torch.abs(RCE_values - rce_val))\n",
    "    predictions.append(y_train[closest_class])\n",
    "\n",
    "# Calculate the classification accuracy\n",
    "accuracy = np.sum(np.array(predictions) == np.array(y_test)) / len(y_test)\n",
    "print(\"Classification accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26b0a1-5433-481b-8078-e77379b3b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess new unlabeled images\n",
    "unlabeled_images_path = 'filesDir'\n",
    "unlabeled_image_size = (100, 100)\n",
    "unlabeled_images = []\n",
    "\n",
    "for filename in os.listdir(unlabeled_images_path):\n",
    "    if filename.endswith('.bmp'):\n",
    "        path = os.path.join(unlabeled_images_path, filename)\n",
    "        img = Image.open(path).convert('RGB').resize(unlabeled_image_size)\n",
    "        img = np.array(img, dtype='float32')\n",
    "        img = 1 - img / 127.5\n",
    "        unlabeled_images.append(img)\n",
    "\n",
    "unlabeled_images = np.array(unlabeled_images)\n",
    "\n",
    "\n",
    "# Move unlabeled images to GPU if available\n",
    "unlabeled_images = torch.tensor(unlabeled_images, device=device)\n",
    "\n",
    "# Classify the unlabeled images\n",
    "unlabeled_predictions = []\n",
    "\n",
    "for i in range(len(unlabeled_images)):\n",
    "    rce_val = rce(unlabeled_images[i], X_train, theta)\n",
    "    closest_class = torch.argmin(torch.abs(RCE_values - rce_val))\n",
    "    unlabeled_predictions.append(y_train[closest_class])\n",
    "\n",
    "# # Print the predicted labels for the new images\n",
    "# for i, prediction in enumerate(unlabeled_predictions):\n",
    "#     print(f\"Image {i+1}: {label_decode[prediction]}\")\n",
    "\n",
    "\n",
    "ground_truth_labels = []  # Replace this with the actual labels for the new images\n",
    "\n",
    "if ground_truth_labels:\n",
    "    accuracy = np.sum(np.array(unlabeled_predictions) == np.array(ground_truth_labels)) / len(ground_truth_labels)\n",
    "    print(\"Classification accuracy for unlabeled images:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e2f229-59c0-40bf-a4d5-c48dce0255a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for class 0 saved to C:\\Users\\azatv\\JupyterProjects\\RCE\\first_test\\Outside stave\\f_Pedal8va_0.png\n",
      "Image for class 1 saved to C:\\Users\\azatv\\JupyterProjects\\RCE\\first_test\\Outside stave\\f_Pedal8va_1.png\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vars import filename, f_reprize_end, f_msimbol_39_end, out_path, f_8va15ma, f_Accent, f_Pedal8va\n",
    "\n",
    "# Read the file content\n",
    "with open(f_Pedal8va, \"r\") as f:\n",
    "    content = f.read()\n",
    "    \n",
    "#doesnt recognize \n",
    "#Name of ID...Unknown_zUnknown ID 457Score  0 9.bmp\n",
    "\n",
    "# Extract the weights and class IDs\n",
    "weights_and_classes = re.findall(r\"ClassID\\s+=\\s+(\\d+)\\s+:.*?:\\s+Weights\\s+=\\s+([\\d\\.,\\s]+)\", content)\n",
    "classes, weights = zip(*weights_and_classes)\n",
    "classes = list(map(int, classes))\n",
    "weights = [list(map(float, w.strip().split(\", \"))) for w in weights]\n",
    "\n",
    "# Convert to a numpy array\n",
    "weights = np.array(weights)\n",
    "\n",
    "# Create a DataFrame with the weights\n",
    "df_weights = pd.DataFrame(weights)\n",
    "df_weights['Class'] = classes\n",
    "\n",
    "# Plot a separate heatmap for each class\n",
    "for class_id in sorted(set(classes)):\n",
    "    class_weights = df_weights[df_weights['Class'] == class_id].drop('Class', axis=1)\n",
    "    #plt.figure(figsize=(15, 100))\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.set()\n",
    "    ax = sns.heatmap(class_weights, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    #ax = sns.heatmap(class_weights.head(100), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    \n",
    "    output_path = f'{out_path}f_Pedal8va_{class_id}.png'\n",
    "    ax.get_figure().savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Image for class {class_id} saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ab60f7-a843-43ca-ad92-54e6b398ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from vars import input_directory, output_file_path\n",
    "\n",
    "# Count the samples for each class\n",
    "def count_samples(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = file.read()\n",
    "        class_counts = defaultdict(int)\n",
    "        midlayer_pattern = re.compile(r\"ClassID = (\\d+) : Ramda\")\n",
    "        matches = midlayer_pattern.findall(data)\n",
    "        for class_id in matches:\n",
    "            class_counts[class_id] += 1\n",
    "    return class_counts\n",
    "\n",
    "# Read dat files from the input directory\n",
    "dat_files = [f for f in os.listdir(input_directory) if f.endswith(\".dat\")]\n",
    "\n",
    "# Write the output to a file\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    for dat_file in dat_files:\n",
    "        file_path = os.path.join(input_directory, dat_file)\n",
    "        counts = count_samples(file_path)\n",
    "        output_file.write(f\"File: {dat_file}\\n\")\n",
    "        for class_id, count in counts.items():\n",
    "            output_file.write(f\"Class {class_id}: {count} samples\\n\")\n",
    "        output_file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25dcaf6-2196-404f-b963-30b5b6a5f2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
