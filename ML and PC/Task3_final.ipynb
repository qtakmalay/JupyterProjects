{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced development shape: (441, 4)\n",
      "Reduced timestamp dataset shape: (441, 175, 44)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load datasets\n",
    "dataset_path = r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\ML and PC\\development.csv\"\n",
    "feature_names_path = r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\ML and PC\\idx_to_feature_name.csv\"\n",
    "timestamp_dataset_path = r\"C:\\Users\\azatv\\Jupyter\\JupyterProjects\\ML and PC\\development.npy\"\n",
    "\n",
    "development = pd.read_csv(dataset_path)\n",
    "idx_to_feature_name = pd.read_csv(feature_names_path)\n",
    "timestamp_dataset = np.load(timestamp_dataset_path)\n",
    "\n",
    "labels = development['word']\n",
    "\n",
    "reduced_size = len(development) // 100\n",
    "\n",
    "unique_labels = labels.unique()\n",
    "samples_per_label = reduced_size // len(unique_labels)\n",
    "\n",
    "reduced_indices = []\n",
    "\n",
    "for label in unique_labels:\n",
    "    label_indices = development[development['word'] == label].index.tolist()\n",
    "    sampled_indices = np.random.choice(label_indices, samples_per_label)\n",
    "    reduced_indices.extend(sampled_indices)\n",
    "\n",
    "reduced_development = development.loc[reduced_indices].reset_index(drop=True)\n",
    "reduced_timestamp_dataset = timestamp_dataset[reduced_indices]\n",
    "\n",
    "print(f\"Reduced development shape: {reduced_development.shape}\")\n",
    "print(f\"Reduced timestamp dataset shape: {reduced_timestamp_dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,y,z :(441, 44, 175)\n",
      "(19404, 175)\n",
      "(19404, 176)\n",
      "   bandwidth_0   centroid_0  contrast_0  contrast_1  contrast_2  contrast_3  \\\n",
      "0  3293.925414  1904.772044    3.254015    2.145693    4.591402    8.548419   \n",
      "1  3401.407879  2003.966470    5.548540    7.209587    6.677888   10.362639   \n",
      "2  3101.558996  1374.951201    6.986853    2.873223   11.016584   11.755014   \n",
      "3  3130.988887  1459.063982    8.080800    3.305663    3.508137    7.832932   \n",
      "4  3252.981235  1716.807020    6.909907    8.106370    7.700668    7.229105   \n",
      "\n",
      "   contrast_4  contrast_5  contrast_6  energy_0  ...  mfcc_d2_26  mfcc_d2_27  \\\n",
      "0   14.942765   10.686919   12.397009  2.588598  ...   -0.007337   -0.055169   \n",
      "1    9.464603   12.222898   11.917046  2.778460  ...   -0.007337   -0.055169   \n",
      "2    8.432297   14.832628   13.527659  3.797681  ...   -0.007337   -0.055169   \n",
      "3    9.460101   18.393203   18.549774  3.190613  ...   -0.007337   -0.055169   \n",
      "4   10.156537    9.865179   11.376497  2.861669  ...   -0.007337   -0.055169   \n",
      "\n",
      "   mfcc_d2_28  mfcc_d2_29  mfcc_d2_30  mfcc_d2_31   power_0   yin_0   zcr_0  \\\n",
      "0   -0.017064    0.014889   -0.034738   -0.001422  0.193099  8000.0  0.1575   \n",
      "1   -0.017064    0.014889   -0.034738   -0.001422  0.324838  8000.0  0.1150   \n",
      "2   -0.017064    0.014889   -0.034738   -0.001422  1.444574  8000.0  0.0100   \n",
      "3   -0.017064    0.014889   -0.034738   -0.001422  0.689549  8000.0  0.0200   \n",
      "4   -0.017064    0.014889   -0.034738   -0.001422  0.515679  8000.0  0.0525   \n",
      "\n",
      "      label  \n",
      "0  Brötchen  \n",
      "1  Brötchen  \n",
      "2  Brötchen  \n",
      "3  Brötchen  \n",
      "4  Brötchen  \n",
      "\n",
      "[5 rows x 176 columns]\n"
     ]
    }
   ],
   "source": [
    "labels_repeated = reduced_development['word'].repeat(44).reset_index(drop=True)\n",
    "\n",
    "reduced_timestamp_dataset = np.swapaxes(reduced_timestamp_dataset, 1, 2)\n",
    "x, y, z = reduced_timestamp_dataset.shape  \n",
    "print(f\"x,y,z :{x,y,z}\")\n",
    "\n",
    "reduced_timestamp_dataset_xyz = reduced_timestamp_dataset.reshape((x * y, z))\n",
    "\n",
    "print(reduced_timestamp_dataset_xyz.shape)\n",
    "df = pd.DataFrame(reduced_timestamp_dataset_xyz)\n",
    "df.columns = list(idx_to_feature_name['feature_name'])\n",
    "df['label'] = labels_repeated\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (15523, 175)\n",
      "Testing set shape: (3881, 175)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "reg.fit(X, y)\n",
    "importance = reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature  importance\n",
      "82        mfcc_6    0.025790\n",
      "109     mfcc_d_1    0.016628\n",
      "108     mfcc_d_0    0.014872\n",
      "110     mfcc_d_2    0.014722\n",
      "143    mfcc_d2_3    0.014689\n",
      "..           ...         ...\n",
      "69   melspect_57    0.002094\n",
      "37   melspect_25    0.002032\n",
      "48   melspect_36    0.001981\n",
      "46   melspect_34    0.001972\n",
      "76        mfcc_0    0.001546\n",
      "\n",
      "[175 rows x 2 columns]\n",
      "Selected important features: ['mfcc_6', 'mfcc_d_1', 'mfcc_d_0', 'mfcc_d_2', 'mfcc_d2_3', 'mfcc_d_4', 'mfcc_d_7', 'mfcc_d_3', 'mfcc_d2_1', 'mfcc_d_6', 'mfcc_d_27', 'mfcc_d2_0', 'mfcc_d_5', 'mfcc_d2_6']\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importance})\n",
    "\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importances)\n",
    "\n",
    "threshold = 0.01\n",
    "important_features = feature_importances[feature_importances['importance'] > threshold]['feature'].tolist()\n",
    "\n",
    "print(f'Selected important features: {important_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "selected_features = df[important_features]\n",
    "labels = df['label']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(selected_features, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_selected = scaler.fit_transform(X_train)\n",
    "X_val_selected = scaler.transform(X_val)\n",
    "X_test_selected = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "Clf: RandomForestClassifier(n_jobs=-1, random_state=42)\n",
      "Best RandomForest parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best RandomForest cross-validation accuracy: 0.5799704237176849\n",
      "Training SVM...\n",
      "Clf: SVC(random_state=42)\n",
      "Best SVM parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best SVM cross-validation accuracy: 0.45430276256789115\n",
      "Training KNN...\n",
      "Clf: KNeighborsClassifier()\n",
      "Best KNN parameters: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best KNN cross-validation accuracy: 0.5755894968417047\n",
      "RandomForest validation accuracy: 0.607317701623293\n",
      "SVM validation accuracy: 0.45581035815511467\n",
      "KNN validation accuracy: 0.6189126513785107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_classifiers = {}\n",
    "for clf_name, clf in classifiers.items():\n",
    "    print(f\"Training {clf_name}...\")\n",
    "    print(f\"Clf: {clf}\")\n",
    "    grid_search = GridSearchCV(clf, param_grids[clf_name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    best_classifiers[clf_name] = grid_search.best_estimator_\n",
    "    print(f\"Best {clf_name} parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best {clf_name} cross-validation accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "for clf_name, clf in best_classifiers.items():\n",
    "    val_accuracy = clf.score(X_val_selected, y_val)\n",
    "    print(f\"{clf_name} validation accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest test accuracy: 0.6137593403761917\n",
      "RandomForest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58       190\n",
      "           1       0.59      0.68      0.63       149\n",
      "           2       0.70      0.77      0.74       201\n",
      "           3       0.57      0.64      0.60       176\n",
      "           4       0.69      0.51      0.58       195\n",
      "           5       0.61      0.63      0.62       180\n",
      "           6       0.58      0.68      0.63       177\n",
      "           7       0.70      0.60      0.65       184\n",
      "           8       0.73      0.53      0.62       192\n",
      "           9       0.63      0.68      0.66       185\n",
      "          10       0.66      0.60      0.63       188\n",
      "          11       0.54      0.60      0.57       177\n",
      "          12       0.61      0.62      0.62       188\n",
      "          13       0.55      0.57      0.56       187\n",
      "          14       0.58      0.51      0.54       171\n",
      "          15       0.52      0.55      0.54       182\n",
      "          16       0.67      0.56      0.61       183\n",
      "          17       0.66      0.59      0.63       177\n",
      "          18       0.55      0.65      0.59       206\n",
      "          19       0.67      0.59      0.63       198\n",
      "          20       0.60      0.73      0.66       195\n",
      "\n",
      "    accuracy                           0.61      3881\n",
      "   macro avg       0.62      0.61      0.61      3881\n",
      "weighted avg       0.62      0.61      0.61      3881\n",
      "\n",
      "SVM test accuracy: 0.4769389332646225\n",
      "SVM classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.48      0.46       190\n",
      "           1       0.54      0.51      0.53       149\n",
      "           2       0.67      0.75      0.71       201\n",
      "           3       0.56      0.63      0.59       176\n",
      "           4       0.59      0.44      0.50       195\n",
      "           5       0.49      0.46      0.48       180\n",
      "           6       0.53      0.46      0.49       177\n",
      "           7       0.56      0.43      0.49       184\n",
      "           8       0.55      0.39      0.45       192\n",
      "           9       0.55      0.55      0.55       185\n",
      "          10       0.57      0.37      0.45       188\n",
      "          11       0.39      0.38      0.39       177\n",
      "          12       0.69      0.68      0.68       188\n",
      "          13       0.26      0.40      0.32       187\n",
      "          14       0.54      0.39      0.46       171\n",
      "          15       0.35      0.41      0.38       182\n",
      "          16       0.48      0.37      0.41       183\n",
      "          17       0.44      0.38      0.41       177\n",
      "          18       0.24      0.55      0.34       206\n",
      "          19       0.51      0.41      0.46       198\n",
      "          20       0.66      0.56      0.61       195\n",
      "\n",
      "    accuracy                           0.48      3881\n",
      "   macro avg       0.51      0.48      0.48      3881\n",
      "weighted avg       0.51      0.48      0.48      3881\n",
      "\n",
      "KNN test accuracy: 0.6207163102293224\n",
      "KNN classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62       190\n",
      "           1       0.61      0.67      0.64       149\n",
      "           2       0.70      0.75      0.72       201\n",
      "           3       0.66      0.70      0.68       176\n",
      "           4       0.62      0.52      0.57       195\n",
      "           5       0.64      0.63      0.63       180\n",
      "           6       0.61      0.64      0.62       177\n",
      "           7       0.65      0.60      0.63       184\n",
      "           8       0.58      0.57      0.58       192\n",
      "           9       0.65      0.72      0.68       185\n",
      "          10       0.66      0.57      0.61       188\n",
      "          11       0.59      0.60      0.59       177\n",
      "          12       0.71      0.64      0.67       188\n",
      "          13       0.51      0.56      0.53       187\n",
      "          14       0.62      0.57      0.59       171\n",
      "          15       0.55      0.60      0.58       182\n",
      "          16       0.66      0.57      0.61       183\n",
      "          17       0.55      0.63      0.59       177\n",
      "          18       0.56      0.57      0.56       206\n",
      "          19       0.59      0.61      0.60       198\n",
      "          20       0.72      0.70      0.71       195\n",
      "\n",
      "    accuracy                           0.62      3881\n",
      "   macro avg       0.62      0.62      0.62      3881\n",
      "weighted avg       0.62      0.62      0.62      3881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "for clf_name, clf in best_classifiers.items():\n",
    "    test_accuracy = clf.score(X_test_selected, y_test)\n",
    "    y_pred = clf.predict(X_test_selected)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"{clf_name} test accuracy: {test_accuracy}\")\n",
    "    print(f\"{clf_name} classification report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dataset_path = r'C:\\Users\\azatv\\Jupyter\\JupyterProjects\\ML and PC\\new_df30.1.csv'\n",
    "df = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Check if GPU is available and set it up\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        print(physical_devices)\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            physical_devices[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]\n",
    "        )\n",
    "        print(f\"Using GPU: {physical_devices[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_onehot = to_categorical(y_encoded)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y_onehot, test_size=0.2, stratify=y_onehot, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1]))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(y_onehot.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_valid, y_valid), verbose=1)\n",
    "\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "valid_loss, valid_accuracy = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "print(f\"Validation Accuracy: {valid_accuracy*100:.2f}%\")\n",
    "\n",
    "model_path = 'linear-softmax0.2.keras'\n",
    "model.save(model_path)\n",
    "print(\"Model saved successfully.\")\n",
    "\n",
    "pred_probs = model.predict(X_valid)\n",
    "pred_labels = np.argmax(pred_probs, axis=1)\n",
    "true_labels = np.argmax(y_valid, axis=1)\n",
    "\n",
    "valid_accuracy = np.mean(pred_labels == true_labels)\n",
    "print(f\"Validation Accuracy: {valid_accuracy*100:.2f}%\")\n",
    "\n",
    "print(classification_report(true_labels, pred_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "\n",
    "# output:\n",
    "\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "# Using GPU: /physical_device:GPU:0\n",
    "# Epoch 1/50\n",
    "# 1641/1641 [==============================] - 5s 2ms/step - loss: 2.8302 - accuracy: 0.1291 - val_loss: 2.7018 - val_accuracy: 0.1670\n",
    "# Epoch 2/50\n",
    "# 1641/1641 [==============================] - 3s 2ms/step - loss: 2.6455 - accuracy: 0.1824 - val_loss: 2.6053 - val_accuracy: 0.1959\n",
    "# Epoch 3/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.5481 - accuracy: 0.2115 - val_loss: 2.5355 - val_accuracy: 0.2139\n",
    "# Epoch 4/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.4569 - accuracy: 0.2396 - val_loss: 2.4545 - val_accuracy: 0.2356\n",
    "# Epoch 5/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.3634 - accuracy: 0.2696 - val_loss: 2.3792 - val_accuracy: 0.2595\n",
    "# Epoch 6/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.2752 - accuracy: 0.2960 - val_loss: 2.3141 - val_accuracy: 0.2834\n",
    "# Epoch 7/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.1918 - accuracy: 0.3190 - val_loss: 2.2625 - val_accuracy: 0.2927\n",
    "# Epoch 8/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.1186 - accuracy: 0.3409 - val_loss: 2.1968 - val_accuracy: 0.3133\n",
    "# Epoch 9/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 2.0528 - accuracy: 0.3576 - val_loss: 2.1601 - val_accuracy: 0.3185\n",
    "# Epoch 10/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 1.9957 - accuracy: 0.3741 - val_loss: 2.1216 - val_accuracy: 0.3311\n",
    "# Epoch 11/50\n",
    "# 1641/1641 [==============================] - 4s 2ms/step - loss: 1.9442 - accuracy: 0.3900 - val_loss: 2.0959 - val_accuracy: 0.3363\n",
    "# Epoch 12/50\n",
    "# ...\n",
    "#     accuracy                           0.39     13121\n",
    "#    macro avg       0.39      0.39      0.39     13121\n",
    "# weighted avg       0.39      0.39      0.39     13121\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wav test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_path = 'linear-softmax0.2.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "feature_names_path = r'C:\\Users\\azatv\\Jupyter\\JupyterProjects\\ML and PC\\idx_to_feature_name.csv'\n",
    "feature_names_df = pd.read_csv(feature_names_path)\n",
    "expected_features = feature_names_df['feature_name'].tolist()\n",
    "\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        if len(y) < 512:\n",
    "            raise ValueError(\"Audio file too short\")\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)[:, :44]\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)[:, :44]\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)[:, :44]\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)[:, :44]\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)[:, :44]\n",
    "\n",
    "        features = np.concatenate((mfccs.flatten(), chroma.flatten(), mel.flatten(), contrast.flatten(), tonnetz.flatten()))\n",
    "\n",
    "        # Ensure total number of features is 174\n",
    "        if len(features) > 174:\n",
    "            features = features[:174]\n",
    "        else:\n",
    "            features = np.pad(features, (0, 174 - len(features)), 'constant')\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "dataset_dir = r'C:\\Users\\azatv\\Jupyter\\JupyterProjects\\ML and PC\\MLPC24_speech_commands_raw_waveforms'\n",
    "\n",
    "def prepare_test_data(dataset_dir, num_samples=10):\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    labels = [label for label in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, label))]\n",
    "    for label in labels:\n",
    "        label_dir = os.path.join(dataset_dir, label)\n",
    "        files = [f for f in os.listdir(label_dir) if not f.startswith(\"._\")]\n",
    "        random_files = random.sample(files, min(num_samples, len(files)))\n",
    "        for file in random_files:\n",
    "            file_path = os.path.join(label_dir, file)\n",
    "            features = extract_features(file_path)\n",
    "            if features is not None:\n",
    "                test_data.append(features)\n",
    "                test_labels.append(label)\n",
    "    return np.array(test_data), np.array(test_labels)\n",
    "\n",
    "X_test, y_test = prepare_test_data(dataset_dir)\n",
    "\n",
    "print(f\"Feature shape: {X_test.shape}\")\n",
    "\n",
    "if X_test.shape[0] == 0:\n",
    "    raise ValueError(\"No valid test data found\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "y_test_onehot = to_categorical(y_test_encoded)\n",
    "\n",
    "pred_probs = model.predict(X_test_scaled)\n",
    "pred_labels = np.argmax(pred_probs, axis=1)\n",
    "true_labels = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "accuracy = np.mean(pred_labels == true_labels)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "print(classification_report(true_labels, pred_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "\n",
    "# output:\n",
    "# Feature shape: (210, 174)\n",
    "# 7/7 [==============================] - 1s 1ms/step\n",
    "# Test Accuracy: 3.33%\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#        Alarm       0.00      0.00      0.00        10\n",
    "#     Brötchen       0.00      0.00      0.00        10\n",
    "#    Fernseher       0.14      0.10      0.12        10\n",
    "#         Haus       0.00      0.00      0.00        10\n",
    "#      Heizung       0.00      0.00      0.00        10\n",
    "#      Leitung       0.08      0.10      0.09        10\n",
    "#        Licht       0.00      0.00      0.00        10\n",
    "#      Lüftung       0.18      0.20      0.19        10\n",
    "#         Ofen       0.00      0.00      0.00        10\n",
    "#        Radio       0.00      0.00      0.00        10\n",
    "#     Schraube       0.00      0.00      0.00        10\n",
    "#      Spiegel       0.00      0.00      0.00        10\n",
    "#  Staubsauger       0.09      0.10      0.10        10\n",
    "#           an       0.17      0.10      0.12        10\n",
    "#          aus       0.00      0.00      0.00        10\n",
    "#         kann       0.00      0.00      0.00        10\n",
    "#        nicht       0.00      0.00      0.00        10\n",
    "#        offen       0.00      0.00      0.00        10\n",
    "#        other       0.07      0.10      0.08        10\n",
    "#         warm       0.00      0.00      0.00        10\n",
    "#    wunderbar       0.00      0.00      0.00        10\n",
    "\n",
    "#     accuracy                           0.03       210\n",
    "#    macro avg       0.04      0.03      0.03       210\n",
    "# weighted avg       0.04      0.03      0.03       210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
